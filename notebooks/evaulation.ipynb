{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba808330",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../figures/dpapt\", exist_ok=True)\n",
    "stats_df = lambda experiment: f\"../results/dpapt/{experiment}/stats.csv\"\n",
    "indiv_hd_df = lambda experiment: f\"../results/dpapt/{experiment}/indiv_hd.csv\"\n",
    "query_df = lambda experiment: f\"../results/dpapt/{experiment}/query_distortion.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_stats = pd.read_csv(stats_df(\"basic\"))\n",
    "basic_stats[\"t_span\"] = basic_stats[\"tu\"] - basic_stats[\"tl\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_center = {\"sample\": False, \"uniform\": False}\n",
    "pp_uniform = {\"sample\": False, \"uniform\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b7d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, filters):\n",
    "    df_filtered = df.copy()\n",
    "    for col, val in filters.items():\n",
    "        if isinstance(val, list):\n",
    "            df_filtered = df_filtered[df_filtered[col].isin(val)]\n",
    "        else:\n",
    "            df_filtered = df_filtered[df_filtered[col] == val]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eb22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineplot(\n",
    "    data, \n",
    "    x_col, \n",
    "    y_col, \n",
    "    weights_col=None,\n",
    "    hue_col=None, \n",
    "    title=\"\", \n",
    "    xlabel=\"x\",\n",
    "    x_ticks=None,\n",
    "    y_ticks=None,\n",
    "    estimator=None,\n",
    "    ylabel=\"y\", \n",
    "    legend_title=None, \n",
    "    ax=None, \n",
    "    out_file=None\n",
    "):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.set_palette(\"colorblind\")\n",
    "    sns.set_context(\"paper\")\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    sns.lineplot(data=data, x=x_col, y=y_col, weights=weights_col, hue=hue_col, estimator=estimator, ax=ax, markers=True, dashes=False)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if hue_col:\n",
    "        ax.legend(title=legend_title)\n",
    "    if x_ticks is not None:\n",
    "        ax.set_xticks(x_ticks)\n",
    "    if y_ticks is not None:\n",
    "        ax.set_yticks(y_ticks)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    if out_file is not None:\n",
    "        plt.savefig(f\"../figures/dpapt/{out_file}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def violinplot(\n",
    "    data, \n",
    "    x_col, \n",
    "    y_col, \n",
    "    hue_col=None,\n",
    "    title=\"\", \n",
    "    xlabel=\"x\",\n",
    "    x_ticks=None,\n",
    "    y_ticks=None,\n",
    "    ylabel=\"y\", \n",
    "    legend_title=None, \n",
    "    ax=None, \n",
    "    out_file=\"vlnplot\"\n",
    "):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.set_palette(\"colorblind\")\n",
    "    sns.set_context(\"paper\")\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    sns.violinplot(data=data, x=x_col, y=y_col, hue=hue_col, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if hue_col:\n",
    "        ax.legend(title=legend_title)\n",
    "    if x_ticks is not None:\n",
    "        ax.set_xticks(x_ticks)\n",
    "    if y_ticks is not None:\n",
    "        ax.set_yticks(y_ticks)\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../figures/dpapt/{out_file}.pdf\", format=\"pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974115c",
   "metadata": {},
   "source": [
    "## Output Data of DPAPT\n",
    "\n",
    "DPAPT publishes a private synopsis consisting of trajectories over **cells** rather than precise points. Each trajectory produced by DPAPT is a sequence of cells, where each cell models some uncertainty of the trajectory at the given time.\n",
    "\n",
    "Because the sanitized database operates over cells, **post-processing** is necessary to derive point-based trajectories that can be meaningfully compared against the original dataset. Post-processing translates each area into a representative point trajectory, enabling the use of traditional spatial utility metrics.\n",
    "\n",
    "In this section, we restrict ourselves to the case where no clustering is applied, and therefore each area consists of exactly one cell. We consider two post-processing strategies:\n",
    "\n",
    "- **Centroid Replacement**:\n",
    "    Each cell is replaced by its geometric center. The resulting trajectory is fully deterministic, but does not model the spatial uncertainty inherent in the cell.\n",
    "\n",
    "- **Uniform Sampling**:  \n",
    "    For each cell, a point is sampled uniformly at random from the cell's interior. This introduces randomness, but captures the spatial uncertainty introduced by the DPAPT mechanism, **under the assumption of uniformity**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee8fbd",
   "metadata": {},
   "source": [
    "\n",
    "## Utility Metrics\n",
    "Following post-processing, we apply different utility metrics to assess the quality of the published database relative to the original one.\n",
    "\n",
    "\n",
    "- **Euclidean Distance between Trajectories**\n",
    "    \n",
    "    The euclidean distance is restricted to trajectories having the same length.\n",
    "    We consider the **pairwise euclidean distance** that computes the euclidean distance between trajectories points for each time step and computes the euclidean distance again on the resulting vector of pairwise distances.\n",
    "    $$\n",
    "    d_2^{\\text{pair}}(T, T') = || ( ||p_1 - p_1'||_2, \\dots, ||p_n - p_n'||_2) ||_2.\n",
    "    $$\n",
    "    By transforming a trajectory $T \\in \\{\\mathbb{R} \\times \\mathbb{R}\\}^t$ of length $t$ into a single $2t$ dimensional point $T^x \\in \\mathbb{R}^{2t}$ by *flattening* the coordinate tuples, the euclidean distance on $\\mathbb{R}^{2t}$ under this transformation is equivalent to the euclidean distance on $\\{\\mathbb{R} \\times \\mathbb{R}\\}$.\n",
    "\n",
    "    In the following we write $||T - T'||_2$ as the euclidean distance of the flattened trajectories $T, T'$.\n",
    "\n",
    "- **Comparing Distances of Trajectories with Different Lengths**\n",
    "\n",
    "    When comparing trajectories of different lengths using Euclidean distance, care must be taken to ensure comparability. Longer trajectories naturally accumulate more error due to having more spatial points. As such, the *raw* Euclidean distance between flattened trajectories is not suitable for comparing utility across runs involving different time intervals.\n",
    "\n",
    "    To address this, we consider the well-known **mean squared error (MSE)** formulation. For two trajectories $ T, T' \\in (\\mathbb{R} \\times \\mathbb{R})^t $, flattened to $ T^x, T'^x \\in \\mathbb{R}^{2t} $, the MSE is given by:\n",
    "    $$\n",
    "    \\text{MSE}(T, T') = \\frac{1}{2t} \\| T^x - T'^x \\|_2^2\n",
    "    $$\n",
    "    where $ 2t $ is the total number of coordinates. However, the MSE is expressed in squared units (e.g., metres squared), which can be difficult to interpret directly.\n",
    "\n",
    "    To obtain a meaningful, unit-consistent distance measure, we take the square root of the MSE:\n",
    "    $$\n",
    "    \\text{RMSE}(T, T') = \\sqrt{ \\frac{1}{2t} \\| T^x - T'^x \\|_2^2 } = \\frac{ \\| T^x - T'^x \\|_2 }{ \\sqrt{2t} }\n",
    "    $$\n",
    "    This **root mean squared error (RMSE)** corresponds to the **average L2 deviation per coordinate** and is expressed in the same units as the coordinate space (e.g., metres). It provides an interpretable and scale-consistent way of comparing distances between trajectories of varying lengths.\n",
    "\n",
    "    We therefore use:\n",
    "    $$\n",
    "    d^{\\text{norm}}(T, T') = \\frac{ \\| T - T' \\|_2 }{ \\sqrt{2t} }\n",
    "    $$\n",
    "    as the default normalised distance throughout this work, where $ T $ and $ T' $ are flattened trajectories. This allows us to compare distances meaningfully across time intervals and privacy budgets.\n",
    "\n",
    "\n",
    "\n",
    "- **Hausdorff Distance**:\n",
    "\n",
    "    Between to trajectory databases $D, D'$ over $\\mathbb{R}^2$ of length $t$, we can calculate for each trajectory in $D$ the distance to each trajectory in the other $D'$ and take the minimum of it.\n",
    "    Taking the maximum from that set of minimal distances, yields the *directed Hausdorff distance*:\n",
    "    $$\n",
    "    HD_d(D, D') = \\max_{T \\in D} \\min_{T' \\in D'} || T - T' ||_2.\n",
    "    $$\n",
    "    Taking the maximum of both directions yields the *symmetric Hausdorff distance* (or just Hausdorff distance):\n",
    "    $$\n",
    "    HD(D, D') = \\max{\\{ HD_d(D, D'), HD_d(D', D) \\}}\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb91d86",
   "metadata": {},
   "source": [
    "## Parameters of DPAPT\n",
    "\n",
    "DPAPT accepts several parameters that influence the structure and quality of its output.\n",
    "\n",
    "- **Time Interval**:\n",
    "  \n",
    "  The time interval `t_int = [t_l, t_u]` specifies the lower and upper time bounds for the trajectories in the supplied dataset.  \n",
    "  For each input trajectory, DPAPT extracts the subtrajectory corresponding to this interval and attempts to reconstruct similar trajectories in the sanitized output.  \n",
    "  Consequently, the published trajectories have length $ |t_u - t_l| + 1 $.  \n",
    "  We refer to the variation of `t_int` as the **time interval range**.\n",
    "\n",
    "- **Privacy Budget $\\varepsilon$**:\n",
    "\n",
    "  The parameter `eps` specifies the total privacy budget allocated to the execution of DPAPT.  \n",
    "  As $\\varepsilon$ increases, less noise is added during privatization, potentially improving the utility of the published data.\n",
    "\n",
    "- **Post-Processing Strategy**:\n",
    "\n",
    "  Post-processing specifies how areas (cells) in the output are converted into point trajectories.  \n",
    "  Two strategies are considered:\n",
    "  \n",
    "  - `center`: replace each cell by its geometric center (deterministic).\n",
    "  - `sample`: uniformly sample a point from within each cell (randomized).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10105d",
   "metadata": {},
   "source": [
    "\n",
    "## Parameter Evaluation\n",
    "\n",
    "In the following, we investigate how the choices of time interval range, privacy budget, and post-processing strategy influence the utility of the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa44d0b7",
   "metadata": {},
   "source": [
    "\n",
    "### Influence of Time Interval Range\n",
    "\n",
    "We expect the influence of the time interval range to be significant due to the way DPAPT constructs sanitized databases.\n",
    "\n",
    "At each time step, DPAPT must account for privacy leakage by injecting **fake trajectories**, proportionally to the number of trajectories accumulated up to the previous step.  \n",
    "This recursive process leads to an **exponential growth of noise** over time.  \n",
    "Consequently, we expect the overall utility to **decrease exponentially** as the time interval range increases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad64144",
   "metadata": {},
   "source": [
    "#### Hausdorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hd_boxplot(df, ax=None, title=None):\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=\"t_span\",\n",
    "        y=\"hd_norm\",\n",
    "        hue=\"eps\",\n",
    "        ax=ax,\n",
    "        palette=\"colorblind\"\n",
    "    )\n",
    "    if title is not None and ax is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1039123",
   "metadata": {},
   "outputs": [],
   "source": [
    "indiv_hd = pd.read_csv(indiv_hd_df(\"basic\"))\n",
    "indiv_hd[\"t_span\"] = indiv_hd[\"tu\"] - indiv_hd[\"tl\"] + 1\n",
    "basic_stats[\"hd_norm\"] = basic_stats[\"hausdorff\"] / np.sqrt(2 * basic_stats[\"t_span\"])\n",
    "indiv_hd[\"indiv_hd_norm\"] = indiv_hd[\"individual_hausdorff\"] / np.sqrt(2 * indiv_hd[\"t_span\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d35d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix_eps = {\"eps\": 1}\n",
    "basic_t_range_center_pp = filter_df(basic_stats, {**pp_center})\n",
    "hd_boxplot(basic_t_range_center_pp, ax=plt.gca(), title=\"Hausdorff Distance (Center PP)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798aca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_t_range_uniform_pp = filter_df(basic_stats, {**pp_uniform})\n",
    "hd_boxplot(basic_t_range_uniform_pp, ax=plt.gca(), title=\"Hausdorff Distance (Uniform PP)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_hd_pp_both = pd.concat([basic_t_range_center_pp, basic_t_range_uniform_pp])\n",
    "eps = 2.0\n",
    "basic_hd_pp_both = filter_df(basic_hd_pp_both, {\"eps\": eps})\n",
    "sns.boxplot(\n",
    "    data=basic_hd_pp_both,\n",
    "    x=\"t_span\",\n",
    "    y=\"hd_norm\",\n",
    "    hue=\"uniform\",\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "plt.title(f\"Hausdorff Distance (eps = {eps})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2826f1a5",
   "metadata": {},
   "source": [
    "The plot above shows the **normalized Hausdorff distance** between the original and published datasets for different time spans and privacy budgets, using the `center` post-processing strategy (cell centroid replacement).\n",
    "\n",
    "We can summarize the following observations:\n",
    "\n",
    "- **No consistent exponential utility degradation** with longer time spans:  \n",
    "  While DPAPT introduces more noise over time, the normalized Hausdorff distance does not increase monotonically. In some cases, utility **improves** slightly with longer trajectories, which seems interesting.\n",
    "  Still, the distance approached is considerably large, indicating that DPAPT produces trajectories with very low utility\n",
    "\n",
    "- **Higher privacy budgets do not guarantee better utility:**\n",
    "  Contrary to expectation, increasing $ \\varepsilon $ does not consistently lead to lower error. This supports the earlier insight that **DPAPT’s internal mechanisms (e.g., grid refinement and prefix tree expansion)** can introduce more noise with higher $ \\varepsilon $, reducing utility in some cases.\n",
    "\n",
    "- **Normalized distances remain substantial**:  \n",
    "  Across all settings, the normalized Hausdorff distances lie between 22–30 km, indicating that even with normalization, the privacy mechanism introduces significant spatial noise. This highlights the **inherent trade-off between privacy and accuracy**, and motivates further investigation into more effective post-processing and grid design strategies.\n",
    "\n",
    "These findings show that utility under DPAPT is governed by more than just privacy budget and trajectory length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dd6e3",
   "metadata": {},
   "source": [
    "#### Individual Hausdorf\n",
    "\n",
    "To better understand the utility of DPAPT beyond worst-case outcomes, we visualize the **distribution** of trajectory errors using the *individual Hausdorff distance*, normalized by time span. Each violin plot shows the distribution of errors across all published trajectories, grouped by time span and privacy budget $ \\varepsilon $, using the `center` post-processing strategy.\n",
    "\n",
    "where the individual Hausdorff distance between a trajectory $T$ and a database $D$ is defined by:\n",
    "\n",
    "$$\n",
    "IndivHD(T, D) = \\min_{T' \\in D} || T - T' ||_2\n",
    "$$\n",
    "\n",
    "- compute IndivHD for every T in D_published"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff3d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = [1.0, 2.0, 3.0]\n",
    "basic_indiv_hd_pp_center = filter_df(indiv_hd, {\"eps\": eps, **pp_center})\n",
    "expanded_indiv_hd = basic_indiv_hd_pp_center.loc[\n",
    "    basic_indiv_hd_pp_center.index.repeat(basic_indiv_hd_pp_center[\"count\"])\n",
    "].reset_index(drop=True)\n",
    "violinplot(\n",
    "    data=expanded_indiv_hd,\n",
    "    x_col=\"t_span\",\n",
    "    y_col=\"indiv_hd_norm\",\n",
    "    hue_col=\"eps\",\n",
    "    title=f\"Individual Hausdorff Distance Normalized by Time Span for different privacy budgets\",\n",
    "    xlabel=\"Time Span\",\n",
    "    x_ticks=basic_indiv_hd_pp_center[\"t_span\"].unique(),\n",
    "    ylabel=\"Normalized Individual Hausdorff Distance (meters)\",\n",
    "    legend_title=\"Epsilon\",\n",
    "    ax=plt.gca(),\n",
    "    out_file=\"basic_indiv_hd_pp_center\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e15d2",
   "metadata": {},
   "source": [
    "We can conclude with the following oberservations\n",
    "\n",
    "- **Consistent degradation with higher privacy budgets**:  \n",
    "  Contrary to the expected behavior of differential privacy mechanisms, higher values of  $\\varepsilon $ (i.e., lower privacy, less noise) do **not** lead to better utility. In fact, DPAPT often performs **worse** at $ \\varepsilon = 3.0 $ than at  $\\varepsilon = 1.0 $, especially as the time span increases.\n",
    "\n",
    "- **Distribution confirms non-monotonicity seen in aggregate metrics**:  \n",
    "  This distributional view supports and sharpens the insight gained from the previous normalized Hausdorff plots — utility does not improve monotonically with increased privacy budget. The effect becomes more pronounced for longer time intervals.\n",
    "\n",
    "- **Broad and heavy-tailed error distributions**:  \n",
    "  For each privacy budget and time span, the error distribution is wide and includes **outliers** with high individual distances. This suggests that while *some* trajectories are reconstructed reasonably well, the predominant fraction experience substantial deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a9df1",
   "metadata": {},
   "source": [
    "### Number of \"Meaningful\" Trajectories\n",
    "\n",
    "Since the previous results showed the counterintuitive trend that increasing the privacy budget does not necessarily lead to improved average utility, we now investigate whether **the absolute number of high-quality (i.e., meaningful) trajectories increases** with $\\varepsilon $.\n",
    "\n",
    "We define a trajectory as *meaningful* if its normalized individual Hausdorff distance falls below the 15th percentile of the overall distribution. For each privacy budget and time span, we count the number of trajectories that meet this criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_indiv_hd_pp_center = filter_df(indiv_hd, {**pp_center})\n",
    "distance_thresh = basic_indiv_hd_pp_center[\"indiv_hd_norm\"].quantile(0.15)\n",
    "\n",
    "meaningful_counts = (\n",
    "    basic_indiv_hd_pp_center\n",
    "    .groupby([\"run\", \"t_span\", \"eps\"], group_keys=False)\n",
    "    .apply(lambda df: (df[\"indiv_hd_norm\"] < distance_thresh).mul(df[\"count\"]).sum())\n",
    "    .reset_index(name=\"count_below_thresh\")\n",
    ")\n",
    "lineplot(\n",
    "    data=meaningful_counts,\n",
    "    x_col=\"t_span\",\n",
    "    y_col=\"count_below_thresh\",\n",
    "    estimator=\"mean\",\n",
    "    hue_col=\"eps\",\n",
    "    title=f\"Counts of Individual Hausdorff Distances below {distance_thresh:.2f} for different privacy budgets\",\n",
    "    xlabel=\"Time Span\",\n",
    "    x_ticks=meaningful_counts[\"t_span\"].unique(),\n",
    "    ylabel=\"Count of Distances below Threshold\",\n",
    "    legend_title=\"Epsilon\",\n",
    "    ax=plt.gca(),\n",
    "    out_file=\"basic_indiv_hd_pp_center_count\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fef58",
   "metadata": {},
   "source": [
    "**Key observations:**\n",
    "\n",
    "- **Higher privacy budgets yield more meaningful trajectories**:  \n",
    "  Despite DPAPT performing worse on average at higher  $\\varepsilon $, the *absolute number* of trajectories with low error increases consistently. This supports the hypothesis that higher  $\\varepsilon$ enables the mechanism to retain more real signal — even if the relative proportion of noise also increases.\n",
    "\n",
    "- **Absolute counts peak around time span = 3, then decline**:  \n",
    "  As time span grows, noise accumulates, but for intermediate lengths the mechanism can still generate a relatively high number of accurate trajectories. For longer time spans, fake trajectories and error propagation begin to dominate again.\n",
    "  The increase in meaningfulness potentially comes from the smoothing effect of the RMSE.\n",
    "\n",
    "This analysis shows that evaluating only worst-case or average errors can obscure important trends. Looking at the **absolute count of useful output** gives a richer picture of how privacy and time interval settings affect practical utility in DPAPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1111841",
   "metadata": {},
   "source": [
    "## Fixing Increasing Universe Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f38a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_usize = pd.read_csv(stats_df(\"eps_agnostic\"))\n",
    "fix_usize[\"t_span\"] = fix_usize[\"tu\"] - fix_usize[\"tl\"] + 1\n",
    "fix_usize[\"hd_norm\"] = fix_usize[\"hausdorff\"] / np.sqrt(2 * fix_usize[\"t_span\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be00b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 100\n",
    "fix_usize_c_center_pp = filter_df(fix_usize, {\"c\": c, **pp_center})\n",
    "hd_boxplot(fix_usize_c_center_pp, ax=plt.gca(), title=\"Hausdorff Distance (Center PP, c=100)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_usize_c_uniform_pp = filter_df(fix_usize, {\"c\": c, **pp_uniform})\n",
    "hd_boxplot(fix_usize_c_uniform_pp, ax=plt.gca(), title=\"Hausdorff Distance (Uniform PP, c=100)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144e5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_usize_indiv_hd = pd.read_csv(indiv_hd_df(\"eps_agnostic\"))\n",
    "fix_usize_indiv_hd[\"t_span\"] = fix_usize_indiv_hd[\"tu\"] - fix_usize_indiv_hd[\"tl\"] + 1\n",
    "fix_usize_indiv_hd[\"indiv_hd_norm\"] = fix_usize_indiv_hd[\"individual_hausdorff\"] / np.sqrt(2 * fix_usize_indiv_hd[\"t_span\"])\n",
    "\n",
    "expanded_indiv_hd = fix_usize_indiv_hd.loc[\n",
    "    fix_usize_indiv_hd.index.repeat(fix_usize_indiv_hd[\"count\"])\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48452994",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter_df(expanded_indiv_hd, pp_center)\n",
    "for eps in [1.0, 2.0, 3.0]:\n",
    "    filtered_eps = filter_df(filtered, ({\"eps\": eps}))\n",
    "    sns.violinplot(\n",
    "        data=expanded_indiv_hd,\n",
    "        x=\"t_span\",\n",
    "        y=\"indiv_hd_norm\",\n",
    "        hue=\"c\",\n",
    "        palette=\"colorblind\",\n",
    "    )\n",
    "    plt.title(f\"Individual Hausdorff Distance Normalized by Time Span for different privacy budgets (eps = {eps})\")\n",
    "    plt.xlabel(\"Time Span\")\n",
    "    plt.ylabel(\"Normalized Individual Hausdorff Distance (meters)\")\n",
    "    \n",
    "    plt.legend(title=\"C Values\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bebdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_span = 5\n",
    "c = 200\n",
    "filtered = filter_df(expanded_indiv_hd, {\"t_span\": t_span, \"c\": c})\n",
    "sns.violinplot(\n",
    "    data=filtered,\n",
    "    x=\"eps\",\n",
    "    y=\"indiv_hd_norm\",\n",
    "    hue=\"uniform\",\n",
    "    split=True,\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "\n",
    "plt.title(f\"RMSE Distribution for Different Timespans (eps = {eps}, c = {c})\")\n",
    "plt.xlabel(\"ε\")\n",
    "plt.ylabel(\"Normalized Individual Hausdorff Distance (meters)\")\n",
    "plt.legend(title=\"Uniform PP\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b1cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_stats = pd.read_csv(stats_df(\"cluster\"))\n",
    "cluster_stats[\"t_span\"] = cluster_stats[\"tu\"] - cluster_stats[\"tl\"] + 1\n",
    "cluster_stats[\"hd_norm\"] = cluster_stats[\"hausdorff\"] / np.sqrt(2 * cluster_stats[\"t_span\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_n = filter_df(cluster_stats, {\"eps\": 6.0})\n",
    "sns.boxplot(\n",
    "    data=cluster_n,\n",
    "    x=\"t_span\",\n",
    "    y=\"hd_norm\",\n",
    "    hue=\"n_clusters\",\n",
    "    palette=\"colorblind\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_idvhd = pd.read_csv(indiv_hd_df(\"cluster\"))\n",
    "cluster_idvhd[\"t_span\"] = cluster_idvhd[\"tu\"] - cluster_idvhd[\"tl\"] + 1\n",
    "cluster_idvhd[\"indiv_hd_norm\"] = cluster_idvhd[\"individual_hausdorff\"] / np.sqrt(2 * cluster_idvhd[\"t_span\"])\n",
    "expanded_indiv_hd = cluster_idvhd.loc[\n",
    "    cluster_idvhd.index.repeat(cluster_idvhd[\"count\"])\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluste_idvhd_n = filter_df(expanded_indiv_hd, {\"eps\": 2.0, \"t_span\": [2, 3, 4]})\n",
    "sns.violinplot(\n",
    "    data=cluste_idvhd_n,\n",
    "    x=\"t_span\",\n",
    "    y=\"indiv_hd_norm\",\n",
    "    hue=\"n_clusters\",\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2573e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_qd = pd.read_csv(query_df(\"cluster\"))\n",
    "cluster_qd[\"t_span\"] = cluster_qd[\"tu\"] - cluster_qd[\"tl\"] + 1\n",
    "cluster_qd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_qd_n = filter_df(cluster_qd, {\"n_clusters\": [20, 40]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(\n",
    "    data=cluster_qd_n,\n",
    "    x=\"eps\",\n",
    "    y=\"psi_distortion_rel\",\n",
    "    hue=\"n_clusters\",\n",
    "    split=True,\n",
    "    palette=\"colorblind\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b558d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
