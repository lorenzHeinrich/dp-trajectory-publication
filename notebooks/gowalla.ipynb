{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0       2010-10-19T23:55:27Z    30.2359091167   -97.7951395833  22847\n",
    "\n",
    "# Load the Gowalla dataset\n",
    "df = pd.read_csv(\n",
    "    \"../gowalla/loc-gowalla_totalCheckins.txt\", \n",
    "    header=None, \n",
    "    names=[\"user\", \"timestamp\", \"latitude\", \"longitude\", \"location_id\"], \n",
    "    sep=None, \n",
    "    engine=\"python\"\n",
    ")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "# Extract the date from the timestamp\n",
    "df[\"date\"] = df[\"timestamp\"].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the dataframe to create a user-day matrix (True/False for check-ins)\n",
    "user_day_matrix = df.groupby([\"user\", \"date\"]).size().unstack(fill_value=0).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_streaks(user_series, m):\n",
    "    \"\"\"Finds all valid non-overlapping m-day streaks in a binary presence series.\"\"\"\n",
    "    streaks = []\n",
    "    current_streak = []\n",
    "\n",
    "    for day, present in user_series.items():\n",
    "        if present:\n",
    "            current_streak.append(day)\n",
    "            if len(current_streak) == m:  # Capture exactly m days\n",
    "                streaks.append(current_streak[:])  # Store a copy of the streak\n",
    "                current_streak = []  # Reset to avoid overlap\n",
    "        else:\n",
    "            current_streak = []  # Reset if a gap occurs\n",
    "\n",
    "    return streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the streak finding function to each user's data\n",
    "m = 3\n",
    "valid_streaks = user_day_matrix.apply(lambda row: find_valid_streaks(row, m), axis=1)\n",
    "\n",
    "valid_users = valid_streaks[valid_streaks.apply(lambda streaks: len(streaks) > 0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(valid_streaks[valid_users].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a lookup table for streaks\n",
    "streak_lookup = []\n",
    "traj_id = 0\n",
    "for user, streaks in valid_streaks.items():\n",
    "    for streak in streaks:\n",
    "        streak_lookup.append({\"user\": user, \"traj_id\": traj_id, \"streak_dates\": streak})\n",
    "        traj_id += 1\n",
    "\n",
    "streak_df = pd.DataFrame(streak_lookup)\n",
    "\n",
    "# Step 2: Merge the streak lookup with the original dataframe for efficient filtering\n",
    "df[\"date\"] = pd.to_datetime(df[\"timestamp\"]).dt.date  # Ensure date format\n",
    "df[\"user\"] = df[\"user\"].astype(str)  # Ensure user column is string type for merging\n",
    "\n",
    "# Explode streak dates to a new dataframe for easy matching\n",
    "exploded_streaks = streak_df.explode(\"streak_dates\")\n",
    "exploded_streaks[\"user\"] = exploded_streaks[\"user\"].astype(str)  # Ensure user column is string type for merging\n",
    "\n",
    "# Merge the original dataframe with exploded streaks to find matching dates\n",
    "merged_df = pd.merge(df, exploded_streaks, left_on=[\"user\", \"date\"], right_on=[\"user\", \"streak_dates\"], how=\"inner\")\n",
    "\n",
    "# Step 3: Drop duplicates (if any)\n",
    "merged_df = merged_df.drop_duplicates(subset=[\"user\", \"date\"])\n",
    "merged_df = merged_df.drop(columns=[\"streak_dates\"])\n",
    "\n",
    "# This results in the final merged trajectories\n",
    "merged_df.to_csv(f\"../gowalla/merged_trajectories_length_{m}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium as fm\n",
    "\n",
    "# take a single trajectory and plot it on a map\n",
    "def plot_trajectory(trajectory, map):\n",
    "    for _, row in trajectory.iterrows():\n",
    "        fm.Marker([row[\"latitude\"], row[\"longitude\"]]).add_to(map)\n",
    "    # Add a line connecting the points\n",
    "    points = trajectory[[\"latitude\", \"longitude\"]].values\n",
    "    fm.PolyLine(points, color=\"blue\", weight=5, opacity=0.7).add_to(map)\n",
    "    return map\n",
    "\n",
    "traj = merged_df[(merged_df[\"user\"] == \"4\") & (merged_df[\"traj_id\"] == 0)].sort_values(\"timestamp\")\n",
    "print(traj)\n",
    "map = fm.Map(location=[traj[\"latitude\"].mean(), traj[\"longitude\"].mean()], zoom_start=10)\n",
    "plot_trajectory(traj, map)\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
